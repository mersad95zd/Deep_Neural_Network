{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is also available at https://github.com/mersad95zd/Deep_Neural_Network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import os\n",
    "from time import time\n",
    "# Load MNIST dataset\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
    "# Import Tensorflow and start a session\n",
    "import tensorflow as tf\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.a. Build and Train a 4-layer DCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "    '''\n",
    "    Initialize weights\n",
    "    :param shape: shape of weights, e.g. [w, h ,Cin, Cout] where\n",
    "    w: width of the filters\n",
    "    h: height of the filters\n",
    "    Cin: the number of the channels of the filters\n",
    "    Cout: the number of filters\n",
    "    :return: a tensor variable for weights with initial values\n",
    "    '''\n",
    "    # IMPLEMENT YOUR WEIGHT_VARIABLE HERE\n",
    "    W = tf.Variable( tf.truncated_normal(shape,stddev=0.05) )\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bias_variable(shape):\n",
    "    '''\n",
    "    Initialize biases\n",
    "    :param shape: shape of biases, e.g. [Cout] where\n",
    "    Cout: the number of filters\n",
    "    :return: a tensor variable for biases with initial values\n",
    "    '''\n",
    "    # IMPLEMENT YOUR BIAS_VARIABLE HERE\n",
    "    b = tf.Variable( tf.constant(0.05 , shape=shape) )\n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(x, W):\n",
    "    '''\n",
    "    Perform 2-D convolution\n",
    "    :param x: input tensor of size [N, W, H, Cin] where\n",
    "    N: the number of images\n",
    "    W: width of images\n",
    "    H: height of images\n",
    "    Cin: the number of channels of images\n",
    "    :param W: weight tensor [w, h, Cin, Cout]\n",
    "    w: width of the filters\n",
    "    h: height of the filters\n",
    "    Cin: the number of the channels of the filters = the number of channels of\n",
    "    images\n",
    "    Cout: the number of filters\n",
    "    :return: a tensor of features extracted by the filters, a.k.a. the results\n",
    "    after convolution\n",
    "    '''\n",
    "    # IMPLEMENT YOUR CONV2D HERE\n",
    "    h_conv = tf.nn.conv2d(x,W,strides=[1,1,1,1],padding='SAME')\n",
    "    return h_conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_pool_2x2(x):\n",
    "    '''\n",
    "    Perform non-overlapping 2-D maxpooling on 2x2 regions in the input data\n",
    "    :param x: input data\n",
    "    :return: the results of maxpooling (max-marginalized + downsampling)\n",
    "    '''\n",
    "    # IMPLEMENT YOUR MAX_POOL_2X2 HERE\n",
    "    h_max = tf.nn.max_pool(x,strides=[1,2,2,1],ksize=[1,2,2,1],padding='SAME')\n",
    "    return h_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Specify training parameters\n",
    "    result_dir = './results/' # directory where the results from the training are saved\n",
    "    max_step = 5500 # the maximum iterations. After max_step iterations, the training will stop no matter what\n",
    "    start_time = time() # start timing\n",
    "    # FILL IN THE CODE BELOW TO BUILD YOUR NETWORK\n",
    "    # placeholders for input data and input labeles\n",
    "    x = tf.placeholder(tf.float32,[None,784],name='x')\n",
    "    y_ = tf.placeholder(tf.float32,[None,10],name='y_')\n",
    "    # reshape the input image\n",
    "    x_image = tf.reshape(x, [-1, 28, 28, 1])\n",
    "    # first convolutional layer\n",
    "    W_conv1 = weight_variable([5,5,1,32])\n",
    "    b_conv1 = bias_variable([32])\n",
    "    h_conv1 = tf.nn.relu(conv2d(x_image,W_conv1) + b_conv1)\n",
    "    h_pool1 = max_pool_2x2(h_conv1)\n",
    "    # second convolutional layer\n",
    "    W_conv2 = weight_variable([5,5,32,64])\n",
    "    b_conv2 = bias_variable([64])\n",
    "    h_conv2 = tf.nn.relu(conv2d(h_pool1,W_conv2) + b_conv2)\n",
    "    h_pool2 = max_pool_2x2(h_conv2)\n",
    "    # densely connected layer\n",
    "    W_fc1 = weight_variable([7*7*64,1024])\n",
    "    b_fc1 = bias_variable([1024])\n",
    "    h_pool2_flat = tf.reshape(h_pool2,[-1,7*7*64])\n",
    "    h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat,W_fc1) + b_fc1)\n",
    "    # dropout\n",
    "    keep_prob = tf.placeholder(tf.float32)\n",
    "    h_fc1_drop = tf.nn.dropout(h_fc1, rate = 1-keep_prob)\n",
    "    # softmax\n",
    "    W_fc2 = weight_variable([1024,10])\n",
    "    b_fc2 = bias_variable([10])\n",
    "    y_conv = tf.nn.softmax(tf.matmul(h_fc1_drop,W_fc2) + b_fc2, name='y_conv')\n",
    "    # FILL IN THE FOLLOWING CODE TO SET UP THE TRAINING\n",
    "    # setup training\n",
    "    cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_*tf.log(y_conv),reduction_indices=[1]))\n",
    "    train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "    correct_prediction = tf.equal(tf.argmax(y_conv,1),tf.argmax(y_,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32),name='accuracy')\n",
    "    # Add a scalar summary for the snapshot loss.\n",
    "    loss_summary = tf.summary.scalar(cross_entropy.op.name, cross_entropy)\n",
    "    \n",
    "    # Build the summary operation based on the TF collection of Summaries.\n",
    "    #summary_op = tf.summary.merge_all()\n",
    "    summary_op = tf.summary.merge([loss_summary])\n",
    "    \n",
    "    # Add the variable initializer Op.\n",
    "    init = tf.initialize_all_variables()\n",
    "    # Create a saver for writing training checkpoints.\n",
    "    saver = tf.train.Saver()\n",
    "    # Instantiate a SummaryWriter to output summaries and the Graph.\n",
    "    summary_writer = tf.summary.FileWriter(result_dir, sess.graph)\n",
    "    # Run the Op to initialize the variables.\n",
    "    sess.run(init)\n",
    "    # run the training\n",
    "    for i in range(max_step):\n",
    "        batch = mnist.train.next_batch(50) # make the data batch, which is used in the training iteration.\n",
    "        # the batch size is 50\n",
    "        if i%100 == 0:\n",
    "            # output the training accuracy every 100 iterations\n",
    "            train_accuracy = accuracy.eval(feed_dict={x:batch[0], y_:batch[1], keep_prob: 1.0})\n",
    "            print(\"step %d, training accuracy %g\"%(i, train_accuracy))\n",
    "            # Update the events file which is used to monitor the training (in this case,\n",
    "            # only the training loss is monitored)\n",
    "            summary_str = sess.run(summary_op, feed_dict={x: batch[0], y_:batch[1], keep_prob: 0.5})\n",
    "            summary_writer.add_summary(summary_str, i)\n",
    "            summary_writer.flush()\n",
    "        # save the checkpoints every 1100 iterations\n",
    "        if i % 1100 == 0 or i == max_step:\n",
    "            checkpoint_file = os.path.join(result_dir, 'checkpoint')\n",
    "            saver.save(sess, checkpoint_file, global_step=i)\n",
    "        train_step.run(feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5}) # run one train_step\n",
    "        #tf.reset_default_graph()\n",
    "    # print test error\n",
    "    print(\"test accuracy %g\"%accuracy.eval(feed_dict={\n",
    "    x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0}))\n",
    "    stop_time = time()\n",
    "    print('The training takes %f second to finish'%(stop_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training accuracy 0.1\n",
      "step 100, training accuracy 0.8\n",
      "step 200, training accuracy 0.92\n",
      "step 300, training accuracy 0.96\n",
      "step 400, training accuracy 0.88\n",
      "step 500, training accuracy 0.92\n",
      "step 600, training accuracy 0.94\n",
      "step 700, training accuracy 0.92\n",
      "step 800, training accuracy 0.96\n",
      "step 900, training accuracy 0.96\n",
      "step 1000, training accuracy 0.88\n",
      "step 1100, training accuracy 0.98\n",
      "step 1200, training accuracy 1\n",
      "step 1300, training accuracy 0.96\n",
      "step 1400, training accuracy 0.96\n",
      "step 1500, training accuracy 0.96\n",
      "step 1600, training accuracy 1\n",
      "step 1700, training accuracy 0.98\n",
      "step 1800, training accuracy 1\n",
      "step 1900, training accuracy 1\n",
      "step 2000, training accuracy 1\n",
      "step 2100, training accuracy 0.96\n",
      "step 2200, training accuracy 1\n",
      "step 2300, training accuracy 0.96\n",
      "step 2400, training accuracy 0.98\n",
      "step 2500, training accuracy 0.98\n",
      "step 2600, training accuracy 1\n",
      "step 2700, training accuracy 0.96\n",
      "step 2800, training accuracy 1\n",
      "step 2900, training accuracy 0.98\n",
      "step 3000, training accuracy 1\n",
      "step 3100, training accuracy 0.98\n",
      "step 3200, training accuracy 0.98\n",
      "step 3300, training accuracy 0.98\n",
      "step 3400, training accuracy 0.96\n",
      "step 3500, training accuracy 0.98\n",
      "step 3600, training accuracy 0.98\n",
      "step 3700, training accuracy 0.98\n",
      "step 3800, training accuracy 0.98\n",
      "step 3900, training accuracy 0.98\n",
      "step 4000, training accuracy 1\n",
      "step 4100, training accuracy 1\n",
      "step 4200, training accuracy 0.98\n",
      "step 4300, training accuracy 1\n",
      "step 4400, training accuracy 0.98\n",
      "step 4500, training accuracy 1\n",
      "step 4600, training accuracy 0.96\n",
      "step 4700, training accuracy 0.98\n",
      "step 4800, training accuracy 0.98\n",
      "step 4900, training accuracy 0.96\n",
      "step 5000, training accuracy 0.98\n",
      "step 5100, training accuracy 1\n",
      "step 5200, training accuracy 1\n",
      "step 5300, training accuracy 1\n",
      "step 5400, training accuracy 1\n",
      "test accuracy 0.9892\n",
      "The training takes 154.122883 second to finish\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may see the image generated by tensorboard below. I installed jupyter-tensorboard instead of using the command line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"loss.PNG\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.b. More on Visualizing Your Training\n",
    "Changes made:\n",
    "1. defining the function variable_summaries which records the statistical summary of the desired variables.\n",
    "2. changed the initialization step so that it sends eachvariable to variable_summaries before moving forward in the code.\n",
    "3. changed summary_op such that it monitors the desired variables.\n",
    "4. defined a new summary variable \"summary_nop\" which is used for monitoring test accuracy.\n",
    "5. tf.summary.merge_all() doesn't work because it merges all placeholders and varibales before this command which is wrong! So you may remove it from the helper code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variable_summaries(var):\n",
    "    \"\"\"Attach a lot of summaries to a Tensor (for TensorBoard visualization).\"\"\"\n",
    "    with tf.name_scope('summaries'):\n",
    "        mean = tf.reduce_mean(var)\n",
    "        m1 = tf.summary.scalar('mean', mean)\n",
    "        with tf.name_scope('stddev'):\n",
    "              stddev = tf.sqrt(tf.reduce_mean(tf.square(var - mean)))\n",
    "        m2 = tf.summary.scalar('stddev', stddev)\n",
    "        m3 = tf.summary.scalar('max', tf.reduce_max(var))\n",
    "        m4 = tf.summary.scalar('min', tf.reduce_min(var))\n",
    "        m5 = tf.summary.histogram('histogram', var)\n",
    "    return m1,m2,m3,m4,m5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Specify training parameters\n",
    "    result_dir = './results/' # directory where the results from the training are saved\n",
    "    max_step = 5500 # the maximum iterations. After max_step iterations, the training will stop no matter what\n",
    "    start_time = time() # start timing\n",
    "    # FILL IN THE CODE BELOW TO BUILD YOUR NETWORK\n",
    "    # placeholders for input data and input labeles\n",
    "    x = tf.placeholder(tf.float32,[None,784],name='x')\n",
    "    y_ = tf.placeholder(tf.float32,[None,10],name='y_')\n",
    "    # reshape the input image\n",
    "    x_image = tf.reshape(x, [-1, 28, 28, 1])\n",
    "    # first convolutional layer\n",
    "    with tf.name_scope(\"layer1\"):\n",
    "        # This Variable will hold the state of the weights for the layer\n",
    "        with tf.name_scope('weights'):\n",
    "            W_conv1 = weight_variable([5,5,1,32])\n",
    "            w1m1,w1m2,w1m3,w1m4,w1m5 = variable_summaries(W_conv1)\n",
    "        with tf.name_scope('biases'):\n",
    "            b_conv1 = bias_variable([32])\n",
    "            b1m1,b1m2,b1m3,b1m4,b1m5 = variable_summaries(b_conv1)\n",
    "        with tf.name_scope('preactivate'):\n",
    "            preactivate1 = conv2d(x_image,W_conv1) + b_conv1\n",
    "            p1m1,p1m2,p1m3,p1m4,p1m5 = variable_summaries(preactivate1)\n",
    "            #tf.summary.histogram('pre_activations', preactivate)\n",
    "        with tf.name_scope('postactivate'):\n",
    "            h_conv1 = tf.nn.relu(preactivate1)\n",
    "            hc1m1,hc1m2,hc1m3,hc1m4,hc1m5 = variable_summaries(h_conv1)\n",
    "            #tf.summar.histogram\n",
    "        with tf.name_scope(\"afterMaxPool\"):\n",
    "            h_pool1 = max_pool_2x2(h_conv1)\n",
    "            hp1m1,hp1m2,hp1m3,hp1m4,hp1m5 = variable_summaries(h_pool1)\n",
    "    \n",
    "    # second convolutional layer\n",
    "    with tf.name_scope(\"layer2\"):\n",
    "        # This Variable will hold the state of the weights for the layer\n",
    "        with tf.name_scope('weights'):\n",
    "            W_conv2 = weight_variable([5,5,32,64])\n",
    "            w2m1,w2m2,w2m3,w2m4,w2m5 = variable_summaries(W_conv2)\n",
    "        with tf.name_scope('biases'):\n",
    "            b_conv2 = bias_variable([64])\n",
    "            b2m1,b2m2,b2m3,b2m4,b2m5 = variable_summaries(b_conv2)\n",
    "        with tf.name_scope('preactivate'):\n",
    "            preactivate2 = conv2d(h_pool1,W_conv2) + b_conv2\n",
    "            p2m1,p2m2,p2m3,p2m4,p2m5 = variable_summaries(preactivate2)\n",
    "            #tf.summary.histogram('pre_activations', preactivate)\n",
    "        with tf.name_scope('postactivate'):\n",
    "            h_conv2 = tf.nn.relu(preactivate2)\n",
    "            hc2m1,hc2m2,hc2m3,hc2m4,hc2m5 = variable_summaries(h_conv2)\n",
    "            #tf.summar.histogram\n",
    "        with tf.name_scope(\"afterMaxPool\"):\n",
    "            h_pool2 = max_pool_2x2(h_conv2)\n",
    "            hp2m1,hp2m2,hp2m3,hp2m4,hp2m5 = variable_summaries(h_pool2)\n",
    "    # densely connected layer\n",
    "    with tf.name_scope(\"layerfc1\"):\n",
    "        # This Variable will hold the state of the weights for the layer\n",
    "        with tf.name_scope('weights'):\n",
    "            W_fc1 = weight_variable([7*7*64,1024])\n",
    "            wf1m1,wf1m2,wf1m3,wf1m4,wf1m5 = variable_summaries(W_fc1)\n",
    "        with tf.name_scope('biases'):\n",
    "            b_fc1 = bias_variable([1024])\n",
    "            bf1m1,bf1m2,bf1m3,bf1m4,bf1m5 = variable_summaries(b_fc1)\n",
    "        with tf.name_scope('preactivate'):\n",
    "            h_pool2_flat = tf.reshape(h_pool2,[-1,7*7*64])\n",
    "            pf1m1,pf1m2,pf1m3,pf1m4,pf1m5 = variable_summaries(h_pool2_flat)\n",
    "            #tf.summar.histogram\n",
    "        with tf.name_scope(\"postactivate\"):\n",
    "            h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat,W_fc1) + b_fc1)\n",
    "            hf1m1,hf1m2,hf1m3,hf1m4,hf1m5 = variable_summaries(h_fc1)\n",
    "    # dropout\n",
    "    keep_prob = tf.placeholder(tf.float32)\n",
    "    h_fc1_drop = tf.nn.dropout(h_fc1, rate = 1-keep_prob)\n",
    "    # softmax\n",
    "    with tf.name_scope(\"layerfc2\"):\n",
    "        # This Variable will hold the state of the weights for the layer\n",
    "        with tf.name_scope('weights'):\n",
    "            W_fc2 = weight_variable([1024,10])\n",
    "            wf2m1,wf2m2,wf2m3,wf2m4,wf2m5 = variable_summaries(W_fc2)\n",
    "        with tf.name_scope('biases'):\n",
    "            b_fc2 = bias_variable([10])\n",
    "            bf2m1,bf2m2,bf2m3,bf2m4,bf2m5 = variable_summaries(b_fc2)\n",
    "        with tf.name_scope('preactivate'):\n",
    "            preactivatefc2 = tf.matmul(h_fc1_drop,W_fc2) + b_fc2\n",
    "            pf2m1,pf2m2,pf2m3,pf2m4,pf2m5 = variable_summaries(preactivatefc2)\n",
    "        with tf.name_scope(\"postactivate\"):\n",
    "            y_conv = tf.nn.softmax(preactivatefc2, name='y_conv')\n",
    "            hf2m1,hf2m2,hf2m3,hf2m4,hf2m5 = variable_summaries(y_conv)\n",
    "    # FILL IN THE FOLLOWING CODE TO SET UP THE TRAINING\n",
    "    # setup training\n",
    "    cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_*tf.log(y_conv),reduction_indices=[1]))\n",
    "    train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "    correct_prediction = tf.equal(tf.argmax(y_conv,1),tf.argmax(y_,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32),name='accuracy')\n",
    "    # Add a scalar summary for the snapshot loss.\n",
    "    loss_summary = tf.summary.scalar(cross_entropy.op.name, cross_entropy)\n",
    "    \n",
    "    # Build the summary operation based on the TF collection of Summaries.\n",
    "    summary_op = tf.summary.merge([loss_summary,w1m1,w1m2,w1m3,w1m4,w1m5, \\\n",
    "                                   b1m1,b1m2,b1m3,b1m4,b1m5,p1m1,p1m2,p1m3,p1m4,p1m5,\\\n",
    "                                   hc1m1,hc1m2,hc1m3,hc1m4,hc1m5,hp1m1,hp1m2,hp1m3,hp1m4,hp1m5, \\\n",
    "                                   w2m1,w2m2,w2m3,w2m4,w2m5, \\\n",
    "                                   b2m1,b2m2,b2m3,b2m4,b2m5,p2m1,p2m2,p2m3,p2m4,p2m5,\\\n",
    "                                   hc2m1,hc2m2,hc2m3,hc2m4,hc2m5,hp2m1,hp2m2,hp2m3,hp2m4,hp2m5, \\\n",
    "                                   wf1m1,wf1m2,wf1m3,wf1m4,wf1m5, \\\n",
    "                                   bf1m1,bf1m2,bf1m3,bf1m4,bf1m5,pf1m1,pf1m2,pf1m3,pf1m4,pf1m5,\\\n",
    "                                   hf1m1,hf1m2,hf1m3,hf1m4,hf1m5, \\\n",
    "                                   wf2m1,wf2m2,wf2m3,wf2m4,wf2m5, \\\n",
    "                                   bf2m1,bf2m2,bf2m3,bf2m4,bf2m5,pf2m1,pf2m2,pf2m3,pf2m4,pf2m5,\\\n",
    "                                   hf2m1,hf2m2,hf2m3,hf2m4,hf2m5])\n",
    "    # summary_nop records summary of test accuracy\n",
    "    summary_nop = tf.summary.merge([tf.summary.scalar(\"test_accuracy\",accuracy)])\n",
    "    # Add the variable initializer Op.\n",
    "    init = tf.initialize_all_variables()\n",
    "    # Create a saver for writing training checkpoints.\n",
    "    saver = tf.train.Saver()\n",
    "    # Instantiate a SummaryWriter to output summaries and the Graph.\n",
    "    summary_writer = tf.summary.FileWriter(result_dir, sess.graph)\n",
    "    # Run the Op to initialize the variables.\n",
    "    sess.run(init)\n",
    "    \n",
    "    train_writer = tf.summary.FileWriter(result_dir + '/train', sess.graph)\n",
    "    test_writer = tf.summary.FileWriter(result_dir + '/test')\n",
    "    def feed_dict(train):\n",
    "        \"\"\"Make a TensorFlow feed_dict: maps data onto Tensor placeholders.\"\"\"\n",
    "        if train:\n",
    "            xs, ys = mnist.train.next_batch(50)\n",
    "            k = 0.5\n",
    "        else:\n",
    "            xs, ys = mnist.test.images, mnist.test.labels\n",
    "            k = 1.0\n",
    "        return {x: xs, y_: ys, keep_prob: k}\n",
    "    # run the training\n",
    "    for i in range(max_step):\n",
    "        \n",
    "        if i % 100 == 0:  # Record summaries and test-set accuracy\n",
    "            train_accuracy = accuracy.eval(feed_dict=feed_dict(False))\n",
    "            print(\"step %d, training accuracy %g\"%(i, train_accuracy))\n",
    "            summary, _ = sess.run([summary_op, train_step], feed_dict=feed_dict(True))\n",
    "            train_writer.add_summary(summary, i)\n",
    "        if i % 1100 == 0:  # Record train set summaries, and train\n",
    "            summary, acc = sess.run([summary_nop,accuracy], feed_dict=feed_dict(False))\n",
    "            test_writer.add_summary(summary, i)\n",
    "        if i % 1100 == 0 or i == max_step-1:\n",
    "            checkpoint_file = os.path.join(result_dir, 'checkpoint')\n",
    "            saver.save(sess, checkpoint_file, global_step=i)\n",
    "            \n",
    "        train_step.run(feed_dict=feed_dict(True)) # run one train_step\n",
    "    # print test error\n",
    "    print(\"test accuracy %g\"%accuracy.eval(feed_dict={\n",
    "    x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0}))\n",
    "    stop_time = time()\n",
    "    print('The training takes %f second to finish'%(stop_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training accuracy 0.1009\n",
      "step 100, training accuracy 0.8614\n",
      "step 200, training accuracy 0.9134\n",
      "step 300, training accuracy 0.9369\n",
      "step 400, training accuracy 0.9453\n",
      "step 500, training accuracy 0.9518\n",
      "step 600, training accuracy 0.9559\n",
      "step 700, training accuracy 0.9607\n",
      "step 800, training accuracy 0.9635\n",
      "step 900, training accuracy 0.9653\n",
      "step 1000, training accuracy 0.9683\n",
      "step 1100, training accuracy 0.9722\n",
      "step 1200, training accuracy 0.9726\n",
      "step 1300, training accuracy 0.9749\n",
      "step 1400, training accuracy 0.9772\n",
      "step 1500, training accuracy 0.9752\n",
      "step 1600, training accuracy 0.9758\n",
      "step 1700, training accuracy 0.9767\n",
      "step 1800, training accuracy 0.9798\n",
      "step 1900, training accuracy 0.9788\n",
      "step 2000, training accuracy 0.9805\n",
      "step 2100, training accuracy 0.98\n",
      "step 2200, training accuracy 0.9806\n",
      "step 2300, training accuracy 0.9811\n",
      "step 2400, training accuracy 0.9823\n",
      "step 2500, training accuracy 0.9838\n",
      "step 2600, training accuracy 0.9838\n",
      "step 2700, training accuracy 0.9841\n",
      "step 2800, training accuracy 0.9838\n",
      "step 2900, training accuracy 0.9841\n",
      "step 3000, training accuracy 0.985\n",
      "step 3100, training accuracy 0.9849\n",
      "step 3200, training accuracy 0.9848\n",
      "step 3300, training accuracy 0.985\n",
      "step 3400, training accuracy 0.9868\n",
      "step 3500, training accuracy 0.9869\n",
      "step 3600, training accuracy 0.9868\n",
      "step 3700, training accuracy 0.9868\n",
      "step 3800, training accuracy 0.9857\n",
      "step 3900, training accuracy 0.9854\n",
      "step 4000, training accuracy 0.9871\n",
      "step 4100, training accuracy 0.9868\n",
      "step 4200, training accuracy 0.9872\n",
      "step 4300, training accuracy 0.9881\n",
      "step 4400, training accuracy 0.9884\n",
      "step 4500, training accuracy 0.9864\n",
      "step 4600, training accuracy 0.9893\n",
      "step 4700, training accuracy 0.9887\n",
      "step 4800, training accuracy 0.9881\n",
      "step 4900, training accuracy 0.9874\n",
      "step 5000, training accuracy 0.9893\n",
      "step 5100, training accuracy 0.9876\n",
      "step 5200, training accuracy 0.9895\n",
      "step 5300, training accuracy 0.9873\n",
      "step 5400, training accuracy 0.9879\n",
      "test accuracy 0.9872\n",
      "The training takes 243.519657 second to finish\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In what follows, you may see a bunch of figures obtained from tensorboard. There were other tags (for different time intervals) of layer_1, but I included the last one here. The order of the images is follows. First, the statistical figures of one layer appears, then its histogram, the comes 2nd layer and so on. This order is also used for point c of this problem (next section)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"layer1_1.PNG\" alt=\"Drawing\" style=\"width: 1500px;\"/>\n",
    "<img src=\"layer1_2.PNG\" alt=\"Drawing\" style=\"width: 1500px;\"/>\n",
    "<img src=\"hist_layer1.PNG\" alt=\"Drawing\" style=\"width: 1500px;\"/>\n",
    "<img src=\"layer2.PNG\" alt=\"Drawing\" style=\"width: 1500px;\"/>\n",
    "<img src=\"layer2_2.PNG\" alt=\"Drawing\" style=\"width: 1500px;\"/>\n",
    "<img src=\"hist_layer2.PNG\" alt=\"Drawing\" style=\"width: 1500px;\"/>\n",
    "<img src=\"layerfc1_1.PNG\" alt=\"Drawing\" style=\"width: 1500px;\"/>\n",
    "<img src=\"layerfc1_2.PNG\" alt=\"Drawing\" style=\"width: 1500px;\"/>\n",
    "<img src=\"hist_layerfc1.PNG\" alt=\"Drawing\" style=\"width: 1500px;\"/>\n",
    "<img src=\"layerfc2_1.PNG\" alt=\"Drawing\" style=\"width: 1500px;\"/>\n",
    "<img src=\"layerfc2_2.PNG\" alt=\"Drawing\" style=\"width: 1500px;\"/>\n",
    "<img src=\"hist_layer_fc2.PNG\" alt=\"Drawing\" style=\"width: 1500px;\"/>\n",
    "<img src=\"test_ac.PNG\" alt=\"Drawing\" style=\"width: 550px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.c. Tome for More Fun!!! :(\n",
    "In this section, I'm going to test the following setups:\n",
    "1. Non-linearity: Tanh, Sigmoid, leaky-ReLu\n",
    "2. Initialization technique: variance_scaling_initializer\n",
    "3. Training algorithm: GradientDescentOptimizer, AdagradOptimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will provide results of using any 3 combinations of these parameters, so there are goining to be a lot of figures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_new(train_func,act_func):\n",
    "    # Specify training parameters\n",
    "    result_dir = './results/' # directory where the results from the training are saved\n",
    "    max_step = 5500 # the maximum iterations. After max_step iterations, the training will stop no matter what\n",
    "    start_time = time() # start timing\n",
    "    # FILL IN THE CODE BELOW TO BUILD YOUR NETWORK\n",
    "    # placeholders for input data and input labeles\n",
    "    x = tf.placeholder(tf.float32,[None,784],name='x')\n",
    "    y_ = tf.placeholder(tf.float32,[None,10],name='y_')\n",
    "    # reshape the input image\n",
    "    x_image = tf.reshape(x, [-1, 28, 28, 1])\n",
    "    # first convolutional layer\n",
    "    with tf.name_scope(\"layer1\"):\n",
    "        # This Variable will hold the state of the weights for the layer\n",
    "        with tf.name_scope('weights'):\n",
    "            W_conv1 = tf.get_variable(\"W_conv1\", shape=[5,5,1,32], \\\n",
    "                                      initializer=tf.contrib.layers.variance_scaling_initializer(1,mode=\"FAN_AVG\",uniform=True))\n",
    "            w1m1,w1m2,w1m3,w1m4,w1m5 = variable_summaries(W_conv1)\n",
    "        with tf.name_scope('biases'):\n",
    "            b_conv1 = tf.Variable(tf.random_normal([32]))\n",
    "            b1m1,b1m2,b1m3,b1m4,b1m5 = variable_summaries(b_conv1)\n",
    "        with tf.name_scope('preactivate'):\n",
    "            preactivate1 = conv2d(x_image,W_conv1) + b_conv1\n",
    "            p1m1,p1m2,p1m3,p1m4,p1m5 = variable_summaries(preactivate1)\n",
    "            #tf.summary.histogram('pre_activations', preactivate)\n",
    "        with tf.name_scope('postactivate'):\n",
    "            h_conv1 = act_func(preactivate1)\n",
    "            hc1m1,hc1m2,hc1m3,hc1m4,hc1m5 = variable_summaries(h_conv1)\n",
    "            #tf.summar.histogram\n",
    "        with tf.name_scope(\"afterMaxPool\"):\n",
    "            h_pool1 = max_pool_2x2(h_conv1)\n",
    "            hp1m1,hp1m2,hp1m3,hp1m4,hp1m5 = variable_summaries(h_pool1)\n",
    "    \n",
    "    # second convolutional layer\n",
    "    with tf.name_scope(\"layer2\"):\n",
    "        # This Variable will hold the state of the weights for the layer\n",
    "        with tf.name_scope('weights'):\n",
    "            W_conv2 = tf.get_variable(\"W_conv2\", shape=[5,5,32,64], \\\n",
    "                                      initializer=tf.contrib.layers.variance_scaling_initializer(2,mode=\"FAN_AVG\",uniform=True))\n",
    "            w2m1,w2m2,w2m3,w2m4,w2m5 = variable_summaries(W_conv2)\n",
    "        with tf.name_scope('biases'):\n",
    "            b_conv2 = tf.Variable(tf.random_normal([64]))\n",
    "            b2m1,b2m2,b2m3,b2m4,b2m5 = variable_summaries(b_conv2)\n",
    "        with tf.name_scope('preactivate'):\n",
    "            preactivate2 = conv2d(h_pool1,W_conv2) + b_conv2\n",
    "            p2m1,p2m2,p2m3,p2m4,p2m5 = variable_summaries(preactivate2)\n",
    "            #tf.summary.histogram('pre_activations', preactivate)\n",
    "        with tf.name_scope('postactivate'):\n",
    "            h_conv2 = act_func(preactivate2)\n",
    "            hc2m1,hc2m2,hc2m3,hc2m4,hc2m5 = variable_summaries(h_conv2)\n",
    "            #tf.summar.histogram\n",
    "        with tf.name_scope(\"afterMaxPool\"):\n",
    "            h_pool2 = max_pool_2x2(h_conv2)\n",
    "            hp2m1,hp2m2,hp2m3,hp2m4,hp2m5 = variable_summaries(h_pool2)\n",
    "    # densely connected layer\n",
    "    with tf.name_scope(\"layerfc1\"):\n",
    "        # This Variable will hold the state of the weights for the layer\n",
    "        with tf.name_scope('weights'):\n",
    "            W_fc1 = tf.get_variable(\"W_fc1\", shape=[7*7*64,1024], initializer=tf.contrib.layers.variance_scaling_initializer())\n",
    "            wf1m1,wf1m2,wf1m3,wf1m4,wf1m5 = variable_summaries(W_fc1)\n",
    "        with tf.name_scope('biases'):\n",
    "            b_fc1 = tf.Variable(tf.random_normal([1024]))\n",
    "            bf1m1,bf1m2,bf1m3,bf1m4,bf1m5 = variable_summaries(b_fc1)\n",
    "        with tf.name_scope('preactivate'):\n",
    "            h_pool2_flat = tf.reshape(h_pool2,[-1,7*7*64])\n",
    "            pf1m1,pf1m2,pf1m3,pf1m4,pf1m5 = variable_summaries(h_pool2_flat)\n",
    "            #tf.summar.histogram\n",
    "        with tf.name_scope(\"postactivate\"):\n",
    "            h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat,W_fc1) + b_fc1)\n",
    "            hf1m1,hf1m2,hf1m3,hf1m4,hf1m5 = variable_summaries(h_fc1)\n",
    "    # dropout\n",
    "    keep_prob = tf.placeholder(tf.float32)\n",
    "    h_fc1_drop = tf.nn.dropout(h_fc1, rate = 1-keep_prob)\n",
    "    # softmax\n",
    "    with tf.name_scope(\"layerfc2\"):\n",
    "        # This Variable will hold the state of the weights for the layer\n",
    "        with tf.name_scope('weights'):\n",
    "            W_fc2 = tf.get_variable(\"W_fc2\", shape=[1024,10], initializer=tf.contrib.layers.variance_scaling_initializer())\n",
    "            wf2m1,wf2m2,wf2m3,wf2m4,wf2m5 = variable_summaries(W_fc2)\n",
    "        with tf.name_scope('biases'):\n",
    "            b_fc2 = tf.Variable(tf.random_normal([10]))\n",
    "            bf2m1,bf2m2,bf2m3,bf2m4,bf2m5 = variable_summaries(b_fc2)\n",
    "        with tf.name_scope('preactivate'):\n",
    "            preactivatefc2 = tf.matmul(h_fc1_drop,W_fc2) + b_fc2\n",
    "            pf2m1,pf2m2,pf2m3,pf2m4,pf2m5 = variable_summaries(preactivatefc2)\n",
    "        with tf.name_scope(\"postactivate\"):\n",
    "            y_conv = tf.nn.softmax(preactivatefc2, name='y_conv')\n",
    "            hf2m1,hf2m2,hf2m3,hf2m4,hf2m5 = variable_summaries(y_conv)\n",
    "    # FILL IN THE FOLLOWING CODE TO SET UP THE TRAINING\n",
    "    # setup training\n",
    "    cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_*tf.log(y_conv),reduction_indices=[1]))\n",
    "    train_step = train_func.minimize(cross_entropy)\n",
    "    correct_prediction = tf.equal(tf.argmax(y_conv,1),tf.argmax(y_,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32),name='accuracy')\n",
    "    # Add a scalar summary for the snapshot loss.\n",
    "    loss_summary = tf.summary.scalar(cross_entropy.op.name, cross_entropy)\n",
    "    \n",
    "    # Build the summary operation based on the TF collection of Summaries.\n",
    "    summary_op = tf.summary.merge([loss_summary,w1m1,w1m2,w1m3,w1m4,w1m5, \\\n",
    "                                   b1m1,b1m2,b1m3,b1m4,b1m5,p1m1,p1m2,p1m3,p1m4,p1m5,\\\n",
    "                                   hc1m1,hc1m2,hc1m3,hc1m4,hc1m5,hp1m1,hp1m2,hp1m3,hp1m4,hp1m5, \\\n",
    "                                   w2m1,w2m2,w2m3,w2m4,w2m5, \\\n",
    "                                   b2m1,b2m2,b2m3,b2m4,b2m5,p2m1,p2m2,p2m3,p2m4,p2m5,\\\n",
    "                                   hc2m1,hc2m2,hc2m3,hc2m4,hc2m5,hp2m1,hp2m2,hp2m3,hp2m4,hp2m5, \\\n",
    "                                   wf1m1,wf1m2,wf1m3,wf1m4,wf1m5, \\\n",
    "                                   bf1m1,bf1m2,bf1m3,bf1m4,bf1m5,pf1m1,pf1m2,pf1m3,pf1m4,pf1m5,\\\n",
    "                                   hf1m1,hf1m2,hf1m3,hf1m4,hf1m5, \\\n",
    "                                   wf2m1,wf2m2,wf2m3,wf2m4,wf2m5, \\\n",
    "                                   bf2m1,bf2m2,bf2m3,bf2m4,bf2m5,pf2m1,pf2m2,pf2m3,pf2m4,pf2m5,\\\n",
    "                                   hf2m1,hf2m2,hf2m3,hf2m4,hf2m5])\n",
    "    # summary_nop records summary of test accuracy\n",
    "    summary_nop = tf.summary.merge([tf.summary.scalar(\"test_accuracy\",accuracy)])\n",
    "    # Add the variable initializer Op.\n",
    "    init = tf.global_variables_initializer()\n",
    "    # Create a saver for writing training checkpoints.\n",
    "    saver = tf.train.Saver()\n",
    "    # Instantiate a SummaryWriter to output summaries and the Graph.\n",
    "    summary_writer = tf.summary.FileWriter(result_dir, sess.graph)\n",
    "    # Run the Op to initialize the variables.\n",
    "    sess.run(init)\n",
    "    \n",
    "    train_writer = tf.summary.FileWriter(result_dir + '/train', sess.graph)\n",
    "    test_writer = tf.summary.FileWriter(result_dir + '/test')\n",
    "    def feed_dict(train):\n",
    "        \"\"\"Make a TensorFlow feed_dict: maps data onto Tensor placeholders.\"\"\"\n",
    "        if train:\n",
    "            xs, ys = mnist.train.next_batch(50)\n",
    "            k = 0.5\n",
    "        else:\n",
    "            xs, ys = mnist.test.images, mnist.test.labels\n",
    "            k = 1.0\n",
    "        return {x: xs, y_: ys, keep_prob: k}\n",
    "    # run the training\n",
    "    for i in range(max_step):\n",
    "        \n",
    "        if i % 100 == 0:  # Record summaries and test-set accuracy\n",
    "            train_accuracy = accuracy.eval(feed_dict=feed_dict(False))\n",
    "            print(\"step %d, training accuracy %g\"%(i, train_accuracy))\n",
    "            summary, _ = sess.run([summary_op, train_step], feed_dict=feed_dict(True))\n",
    "            train_writer.add_summary(summary, i)\n",
    "        if i % 1100 == 0:  # Record train set summaries, and train\n",
    "            summary, acc = sess.run([summary_nop,accuracy], feed_dict=feed_dict(False))\n",
    "            test_writer.add_summary(summary, i)\n",
    "        if i % 1100 == 0 or i == max_step-1:\n",
    "            checkpoint_file = os.path.join(result_dir, 'checkpoint')\n",
    "            saver.save(sess, checkpoint_file, global_step=i)\n",
    "            \n",
    "        train_step.run(feed_dict=feed_dict(True)) # run one train_step\n",
    "    # print test error\n",
    "    print(\"test accuracy %g\"%accuracy.eval(feed_dict={\n",
    "    x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0}))\n",
    "    stop_time = time()\n",
    "    print('The training takes %f second to finish'%(stop_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_color = \"\\033[91m {}\\033[00m\"\n",
    "bold = \"\\033[1m\"\n",
    "bolde = \"\\033[0m\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mSetup #1:\u001b[0m \u001b[91m GradientDescentOptimizer, tanh activation\u001b[00m\n",
      "step 0, training accuracy 0.0892\n",
      "step 100, training accuracy 0.1339\n",
      "step 200, training accuracy 0.7707\n",
      "step 300, training accuracy 0.8863\n",
      "step 400, training accuracy 0.9033\n",
      "step 500, training accuracy 0.9438\n",
      "step 600, training accuracy 0.9515\n",
      "step 700, training accuracy 0.9569\n",
      "step 800, training accuracy 0.9611\n",
      "step 900, training accuracy 0.9615\n",
      "step 1000, training accuracy 0.9655\n",
      "step 1100, training accuracy 0.9688\n",
      "step 1200, training accuracy 0.9719\n",
      "step 1300, training accuracy 0.9741\n",
      "step 1400, training accuracy 0.9729\n",
      "step 1500, training accuracy 0.9759\n",
      "step 1600, training accuracy 0.978\n",
      "step 1700, training accuracy 0.9788\n",
      "step 1800, training accuracy 0.9782\n",
      "step 1900, training accuracy 0.981\n",
      "step 2000, training accuracy 0.9802\n",
      "step 2100, training accuracy 0.9809\n",
      "step 2200, training accuracy 0.9817\n",
      "step 2300, training accuracy 0.9818\n",
      "step 2400, training accuracy 0.982\n",
      "step 2500, training accuracy 0.9833\n",
      "step 2600, training accuracy 0.984\n",
      "step 2700, training accuracy 0.9845\n",
      "step 2800, training accuracy 0.9853\n",
      "step 2900, training accuracy 0.9839\n",
      "step 3000, training accuracy 0.9858\n",
      "step 3100, training accuracy 0.9864\n",
      "step 3200, training accuracy 0.9871\n",
      "step 3300, training accuracy 0.9852\n",
      "step 3400, training accuracy 0.9853\n",
      "step 3500, training accuracy 0.9869\n",
      "step 3600, training accuracy 0.9881\n",
      "step 3700, training accuracy 0.9862\n",
      "step 3800, training accuracy 0.9865\n",
      "step 3900, training accuracy 0.9874\n",
      "step 4000, training accuracy 0.9853\n",
      "step 4100, training accuracy 0.9883\n",
      "step 4200, training accuracy 0.9871\n",
      "step 4300, training accuracy 0.9868\n",
      "step 4400, training accuracy 0.9868\n",
      "step 4500, training accuracy 0.9887\n",
      "step 4600, training accuracy 0.9881\n",
      "step 4700, training accuracy 0.9892\n",
      "step 4800, training accuracy 0.9874\n",
      "step 4900, training accuracy 0.9896\n",
      "step 5000, training accuracy 0.9899\n",
      "step 5100, training accuracy 0.9888\n",
      "step 5200, training accuracy 0.99\n",
      "step 5300, training accuracy 0.985\n",
      "step 5400, training accuracy 0.9902\n",
      "test accuracy 0.9908\n",
      "The training takes 209.310228 second to finish\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    case = \"{}{}{}\".format(bold,\"Setup #1:\",bolde)\n",
    "    print(case,red_color.format(\"GradientDescentOptimizer, tanh activation\"))\n",
    "    tf.reset_default_graph() \n",
    "    sess = tf.InteractiveSession()\n",
    "    main_new(tf.train.GradientDescentOptimizer(5e-2),tf.nn.tanh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here comes the figures:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./s1/layer1_1.PNG\" alt=\"Drawing\" style=\"width: 1500px;\"/>\n",
    "<img src=\"./s1/layer1_2.PNG\" alt=\"Drawing\" style=\"width: 1500px;\"/>\n",
    "<img src=\"./s1/hist_layer1.PNG\" alt=\"Drawing\" style=\"width: 1500px;\"/>\n",
    "<img src=\"./s1/layer2_1.PNG\" alt=\"Drawing\" style=\"width: 1500px;\"/>\n",
    "<img src=\"./s1/layer2_2.PNG\" alt=\"Drawing\" style=\"width: 1500px;\"/>\n",
    "<img src=\"./s1/hist_layer2.PNG\" alt=\"Drawing\" style=\"width: 1500px;\"/>\n",
    "<img src=\"./s1/layerfc1_1.PNG\" alt=\"Drawing\" style=\"width: 1500px;\"/>\n",
    "<img src=\"./s1/layerfc1_2.PNG\" alt=\"Drawing\" style=\"width: 1500px;\"/>\n",
    "<img src=\"./s1/hist_layerfc1.PNG\" alt=\"Drawing\" style=\"width: 1500px;\"/>\n",
    "<img src=\"./s1/layerfc2_1.PNG\" alt=\"Drawing\" style=\"width: 1500px;\"/>\n",
    "<img src=\"./s1/layerfc2_2.PNG\" alt=\"Drawing\" style=\"width: 1500px;\"/>\n",
    "<img src=\"./s1/hist_layerfc2.PNG\" alt=\"Drawing\" style=\"width: 1500px;\"/>\n",
    "<img src=\"./s1/test_ac.PNG\" alt=\"Drawing\" style=\"width: 550px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mSetup #2:\u001b[0m \u001b[91m AdagradOptimizer, tanh activation\u001b[00m\n",
      "step 0, training accuracy 0.1028\n",
      "step 100, training accuracy 0.4191\n",
      "step 200, training accuracy 0.8625\n",
      "step 300, training accuracy 0.8946\n",
      "step 400, training accuracy 0.9214\n",
      "step 500, training accuracy 0.9269\n",
      "step 600, training accuracy 0.9378\n",
      "step 700, training accuracy 0.9406\n",
      "step 800, training accuracy 0.9516\n",
      "step 900, training accuracy 0.952\n",
      "step 1000, training accuracy 0.9571\n",
      "step 1100, training accuracy 0.9578\n",
      "step 1200, training accuracy 0.9578\n",
      "step 1300, training accuracy 0.965\n",
      "step 1400, training accuracy 0.9666\n",
      "step 1500, training accuracy 0.9656\n",
      "step 1600, training accuracy 0.9682\n",
      "step 1700, training accuracy 0.9699\n",
      "step 1800, training accuracy 0.9677\n",
      "step 1900, training accuracy 0.9709\n",
      "step 2000, training accuracy 0.972\n",
      "step 2100, training accuracy 0.9735\n",
      "step 2200, training accuracy 0.9742\n",
      "step 2300, training accuracy 0.9758\n",
      "step 2400, training accuracy 0.9744\n",
      "step 2500, training accuracy 0.9763\n",
      "step 2600, training accuracy 0.9743\n",
      "step 2700, training accuracy 0.9755\n",
      "step 2800, training accuracy 0.9778\n",
      "step 2900, training accuracy 0.9784\n",
      "step 3000, training accuracy 0.9798\n",
      "step 3100, training accuracy 0.9801\n",
      "step 3200, training accuracy 0.9788\n",
      "step 3300, training accuracy 0.9799\n",
      "step 3400, training accuracy 0.98\n",
      "step 3500, training accuracy 0.9801\n",
      "step 3600, training accuracy 0.9816\n",
      "step 3700, training accuracy 0.98\n",
      "step 3800, training accuracy 0.9832\n",
      "step 3900, training accuracy 0.9823\n",
      "step 4000, training accuracy 0.981\n",
      "step 4100, training accuracy 0.9821\n",
      "step 4200, training accuracy 0.9835\n",
      "step 4300, training accuracy 0.983\n",
      "step 4400, training accuracy 0.9836\n",
      "step 4500, training accuracy 0.9828\n",
      "step 4600, training accuracy 0.983\n",
      "step 4700, training accuracy 0.9834\n",
      "step 4800, training accuracy 0.9829\n",
      "step 4900, training accuracy 0.9833\n",
      "step 5000, training accuracy 0.9847\n",
      "step 5100, training accuracy 0.9839\n",
      "step 5200, training accuracy 0.983\n",
      "step 5300, training accuracy 0.9833\n",
      "step 5400, training accuracy 0.9847\n",
      "test accuracy 0.9847\n",
      "The training takes 215.960369 second to finish\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    case = \"{}{}{}\".format(bold,\"Setup #2:\",bolde)\n",
    "    print(case,red_color.format(\"AdagradOptimizer, tanh activation\"))\n",
    "    tf.reset_default_graph() \n",
    "    sess = tf.InteractiveSession()\n",
    "    main_new(tf.train.AdagradOptimizer(1e-2),tf.nn.tanh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the results:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./s2/layer1_1.PNG\" alt=\"Drawing\" style=\"width: 1500px;\"/>\n",
    "<img src=\"./s2/layer1_2.PNG\" alt=\"Drawing\" style=\"width: 1500px;\"/>\n",
    "<img src=\"./s2/hist_layer1.PNG\" alt=\"Drawing\" style=\"width: 1500px;\"/>\n",
    "<img src=\"./s2/layer2_1.PNG\" alt=\"Drawing\" style=\"width: 1500px;\"/>\n",
    "<img src=\"./s2/layer2_2.PNG\" alt=\"Drawing\" style=\"width: 1500px;\"/>\n",
    "<img src=\"./s2/hist_layer2.PNG\" alt=\"Drawing\" style=\"width: 1500px;\"/>\n",
    "<img src=\"./s2/layerfc1_1.PNG\" alt=\"Drawing\" style=\"width: 1500px;\"/>\n",
    "<img src=\"./s2/layerfc1_2.PNG\" alt=\"Drawing\" style=\"width: 1500px;\"/>\n",
    "<img src=\"./s2/hist_layerfc1.PNG\" alt=\"Drawing\" style=\"width: 1500px;\"/>\n",
    "<img src=\"./s2/layerfc2_1.PNG\" alt=\"Drawing\" style=\"width: 1500px;\"/>\n",
    "<img src=\"./s2/layerfc2_2.PNG\" alt=\"Drawing\" style=\"width: 1500px;\"/>\n",
    "<img src=\"./s2/hist_layerfc2.PNG\" alt=\"Drawing\" style=\"width: 1500px;\"/>\n",
    "<img src=\"./s2/test_ac.PNG\" alt=\"Drawing\" style=\"width: 550px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mSetup #3:\u001b[0m \u001b[91m GradientDescentOptimizer, sigmoid activation\u001b[00m\n",
      "step 0, training accuracy 0.1135\n",
      "step 100, training accuracy 0.1135\n",
      "step 200, training accuracy 0.101\n",
      "step 300, training accuracy 0.1135\n",
      "step 400, training accuracy 0.1135\n",
      "step 500, training accuracy 0.1028\n",
      "step 600, training accuracy 0.0982\n",
      "step 700, training accuracy 0.1032\n",
      "step 800, training accuracy 0.1135\n",
      "step 900, training accuracy 0.1135\n",
      "step 1000, training accuracy 0.1135\n",
      "step 1100, training accuracy 0.1032\n",
      "step 1200, training accuracy 0.1032\n",
      "step 1300, training accuracy 0.1893\n",
      "step 1400, training accuracy 0.2079\n",
      "step 1500, training accuracy 0.1031\n",
      "step 1600, training accuracy 0.0989\n",
      "step 1700, training accuracy 0.2703\n",
      "step 1800, training accuracy 0.1601\n",
      "step 1900, training accuracy 0.1403\n",
      "step 2000, training accuracy 0.6055\n",
      "step 2100, training accuracy 0.7121\n",
      "step 2200, training accuracy 0.7743\n",
      "step 2300, training accuracy 0.8169\n",
      "step 2400, training accuracy 0.8008\n",
      "step 2500, training accuracy 0.8411\n",
      "step 2600, training accuracy 0.8645\n",
      "step 2700, training accuracy 0.8717\n",
      "step 2800, training accuracy 0.8635\n",
      "step 2900, training accuracy 0.8849\n",
      "step 3000, training accuracy 0.8927\n",
      "step 3100, training accuracy 0.896\n",
      "step 3200, training accuracy 0.9049\n",
      "step 3300, training accuracy 0.9079\n",
      "step 3400, training accuracy 0.9066\n",
      "step 3500, training accuracy 0.9142\n",
      "step 3600, training accuracy 0.9217\n",
      "step 3700, training accuracy 0.9249\n",
      "step 3800, training accuracy 0.9146\n",
      "step 3900, training accuracy 0.9291\n",
      "step 4000, training accuracy 0.9266\n",
      "step 4100, training accuracy 0.9309\n",
      "step 4200, training accuracy 0.9271\n",
      "step 4300, training accuracy 0.9395\n",
      "step 4400, training accuracy 0.942\n",
      "step 4500, training accuracy 0.941\n",
      "step 4600, training accuracy 0.9439\n",
      "step 4700, training accuracy 0.9458\n",
      "step 4800, training accuracy 0.9472\n",
      "step 4900, training accuracy 0.9468\n",
      "step 5000, training accuracy 0.9494\n",
      "step 5100, training accuracy 0.9497\n",
      "step 5200, training accuracy 0.9459\n",
      "step 5300, training accuracy 0.9511\n",
      "step 5400, training accuracy 0.954\n",
      "test accuracy 0.9547\n",
      "The training takes 209.592605 second to finish\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    case = \"{}{}{}\".format(bold,\"Setup #3:\",bolde)\n",
    "    print(case,red_color.format(\"GradientDescentOptimizer, sigmoid activation\"))\n",
    "    tf.reset_default_graph() \n",
    "    sess = tf.InteractiveSession()\n",
    "    main_new(tf.train.GradientDescentOptimizer(5e-2),tf.nn.sigmoid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./s3/layer1_1.PNG\" alt=\"Drawing\" style=\"width: 1500px;\"/>\n",
    "<img src=\"./s3/layer1_2.PNG\" alt=\"Drawing\" style=\"width: 1500px;\"/>\n",
    "<img src=\"./s3/hist_layer1.PNG\" alt=\"Drawing\" style=\"width: 1500px;\"/>\n",
    "<img src=\"./s3/layer2_1.PNG\" alt=\"Drawing\" style=\"width: 1500px;\"/>\n",
    "<img src=\"./s3/layer2_2.PNG\" alt=\"Drawing\" style=\"width: 1500px;\"/>\n",
    "<img src=\"./s3/hist_layer2.PNG\" alt=\"Drawing\" style=\"width: 1500px;\"/>\n",
    "<img src=\"./s3/layerfc1_1.PNG\" alt=\"Drawing\" style=\"width: 1500px;\"/>\n",
    "<img src=\"./s3/layerfc1_2.PNG\" alt=\"Drawing\" style=\"width: 1500px;\"/>\n",
    "<img src=\"./s3/hist_layerfc1.PNG\" alt=\"Drawing\" style=\"width: 1500px;\"/>\n",
    "<img src=\"./s3/layerfc2_1.PNG\" alt=\"Drawing\" style=\"width: 1500px;\"/>\n",
    "<img src=\"./s3/layerfc2_2.PNG\" alt=\"Drawing\" style=\"width: 1500px;\"/>\n",
    "<img src=\"./s3/hist_layerfc2.PNG\" alt=\"Drawing\" style=\"width: 1500px;\"/>\n",
    "<img src=\"./s3/test_ac.PNG\" alt=\"Drawing\" style=\"width: 550px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mSetup #4:\u001b[0m \u001b[91m AdagradOptimizer, sigmoid activation\u001b[00m\n",
      "step 0, training accuracy 0.0892\n",
      "step 100, training accuracy 0.1135\n",
      "step 200, training accuracy 0.1009\n",
      "step 300, training accuracy 0.0974\n",
      "step 400, training accuracy 0.1028\n",
      "step 500, training accuracy 0.1028\n",
      "step 600, training accuracy 0.1009\n",
      "step 700, training accuracy 0.098\n",
      "step 800, training accuracy 0.1028\n",
      "step 900, training accuracy 0.1135\n",
      "step 1000, training accuracy 0.1135\n",
      "step 1100, training accuracy 0.113\n",
      "step 1200, training accuracy 0.1009\n",
      "step 1300, training accuracy 0.1814\n",
      "step 1400, training accuracy 0.1135\n",
      "step 1500, training accuracy 0.1135\n",
      "step 1600, training accuracy 0.1586\n",
      "step 1700, training accuracy 0.2388\n",
      "step 1800, training accuracy 0.319\n",
      "step 1900, training accuracy 0.3918\n",
      "step 2000, training accuracy 0.3458\n",
      "step 2100, training accuracy 0.6586\n",
      "step 2200, training accuracy 0.8021\n",
      "step 2300, training accuracy 0.8677\n",
      "step 2400, training accuracy 0.8895\n",
      "step 2500, training accuracy 0.9045\n",
      "step 2600, training accuracy 0.9157\n",
      "step 2700, training accuracy 0.9204\n",
      "step 2800, training accuracy 0.9273\n",
      "step 2900, training accuracy 0.9262\n",
      "step 3000, training accuracy 0.9306\n",
      "step 3100, training accuracy 0.9408\n",
      "step 3200, training accuracy 0.9389\n",
      "step 3300, training accuracy 0.9446\n",
      "step 3400, training accuracy 0.9446\n",
      "step 3500, training accuracy 0.9477\n",
      "step 3600, training accuracy 0.9508\n",
      "step 3700, training accuracy 0.954\n",
      "step 3800, training accuracy 0.9555\n",
      "step 3900, training accuracy 0.9533\n",
      "step 4000, training accuracy 0.9568\n",
      "step 4100, training accuracy 0.955\n",
      "step 4200, training accuracy 0.9602\n",
      "step 4300, training accuracy 0.9581\n",
      "step 4400, training accuracy 0.9612\n",
      "step 4500, training accuracy 0.9625\n",
      "step 4600, training accuracy 0.9637\n",
      "step 4700, training accuracy 0.9645\n",
      "step 4800, training accuracy 0.9644\n",
      "step 4900, training accuracy 0.9649\n",
      "step 5000, training accuracy 0.9682\n",
      "step 5100, training accuracy 0.967\n",
      "step 5200, training accuracy 0.9667\n",
      "step 5300, training accuracy 0.9687\n",
      "step 5400, training accuracy 0.9688\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/training/saver.py:960: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n",
      "test accuracy 0.9681\n",
      "The training takes 216.250206 second to finish\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    case = \"{}{}{}\".format(bold,\"Setup #4:\",bolde)\n",
    "    print(case,red_color.format(\"AdagradOptimizer, sigmoid activation\"))\n",
    "    tf.reset_default_graph() \n",
    "    sess = tf.InteractiveSession()\n",
    "    main_new(tf.train.AdagradOptimizer(5e-2),tf.nn.sigmoid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./s4/layer1_1.PNG\" alt=\"Drawing\" style=\"width: 1500px;\"/>\n",
    "<img src=\"./s4/layer1_2.PNG\" alt=\"Drawing\" style=\"width: 1500px;\"/>\n",
    "<img src=\"./s4/hist_layer1.PNG\" alt=\"Drawing\" style=\"width: 1500px;\"/>\n",
    "<img src=\"./s4/layer2_1.PNG\" alt=\"Drawing\" style=\"width: 1500px;\"/>\n",
    "<img src=\"./s4/layer2_2.PNG\" alt=\"Drawing\" style=\"width: 1500px;\"/>\n",
    "<img src=\"./s4/hist_layer2.PNG\" alt=\"Drawing\" style=\"width: 1500px;\"/>\n",
    "<img src=\"./s4/layerfc1_1.PNG\" alt=\"Drawing\" style=\"width: 1500px;\"/>\n",
    "<img src=\"./s4/layerfc1_2.PNG\" alt=\"Drawing\" style=\"width: 1500px;\"/>\n",
    "<img src=\"./s4/hist_layerfc1.PNG\" alt=\"Drawing\" style=\"width: 1500px;\"/>\n",
    "<img src=\"./s4/layerfc2_1.PNG\" alt=\"Drawing\" style=\"width: 1500px;\"/>\n",
    "<img src=\"./s4/layerfc2_2.PNG\" alt=\"Drawing\" style=\"width: 1500px;\"/>\n",
    "<img src=\"./s4/hist_layerfc2.PNG\" alt=\"Drawing\" style=\"width: 1500px;\"/>\n",
    "<img src=\"./s4/test_ac.PNG\" alt=\"Drawing\" style=\"width: 550px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mSetup #5:\u001b[0m \u001b[91m GradientDescentOptimizer, leaky_relu activation\u001b[00m\n",
      "step 0, training accuracy 0.1009\n",
      "step 100, training accuracy 0.1154\n",
      "step 200, training accuracy 0.2205\n",
      "step 300, training accuracy 0.775\n",
      "step 400, training accuracy 0.8373\n",
      "step 500, training accuracy 0.8967\n",
      "step 600, training accuracy 0.9025\n",
      "step 700, training accuracy 0.9228\n",
      "step 800, training accuracy 0.929\n",
      "step 900, training accuracy 0.9324\n",
      "step 1000, training accuracy 0.9368\n",
      "step 1100, training accuracy 0.9436\n",
      "step 1200, training accuracy 0.9479\n",
      "step 1300, training accuracy 0.9482\n",
      "step 1400, training accuracy 0.9513\n",
      "step 1500, training accuracy 0.9513\n",
      "step 1600, training accuracy 0.953\n",
      "step 1700, training accuracy 0.9535\n",
      "step 1800, training accuracy 0.9552\n",
      "step 1900, training accuracy 0.9601\n",
      "step 2000, training accuracy 0.9621\n",
      "step 2100, training accuracy 0.9628\n",
      "step 2200, training accuracy 0.9658\n",
      "step 2300, training accuracy 0.9641\n",
      "step 2400, training accuracy 0.9669\n",
      "step 2500, training accuracy 0.9675\n",
      "step 2600, training accuracy 0.9681\n",
      "step 2700, training accuracy 0.9677\n",
      "step 2800, training accuracy 0.9703\n",
      "step 2900, training accuracy 0.9708\n",
      "step 3000, training accuracy 0.9686\n",
      "step 3100, training accuracy 0.9713\n",
      "step 3200, training accuracy 0.9715\n",
      "step 3300, training accuracy 0.9749\n",
      "step 3400, training accuracy 0.9723\n",
      "step 3500, training accuracy 0.9755\n",
      "step 3600, training accuracy 0.9736\n",
      "step 3700, training accuracy 0.9743\n",
      "step 3800, training accuracy 0.9744\n",
      "step 3900, training accuracy 0.9777\n",
      "step 4000, training accuracy 0.9752\n",
      "step 4100, training accuracy 0.9766\n",
      "step 4200, training accuracy 0.9765\n",
      "step 4300, training accuracy 0.9771\n",
      "step 4400, training accuracy 0.9757\n",
      "step 4500, training accuracy 0.979\n",
      "step 4600, training accuracy 0.978\n",
      "step 4700, training accuracy 0.9746\n",
      "step 4800, training accuracy 0.9785\n",
      "step 4900, training accuracy 0.9778\n",
      "step 5000, training accuracy 0.9784\n",
      "step 5100, training accuracy 0.978\n",
      "step 5200, training accuracy 0.9783\n",
      "step 5300, training accuracy 0.9802\n",
      "step 5400, training accuracy 0.9783\n",
      "test accuracy 0.9801\n",
      "The training takes 209.677805 second to finish\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    case = \"{}{}{}\".format(bold,\"Setup #5:\",bolde)\n",
    "    print(case,red_color.format(\"GradientDescentOptimizer, leaky_relu activation\"))\n",
    "    tf.reset_default_graph() \n",
    "    sess = tf.InteractiveSession()\n",
    "    main_new(tf.train.GradientDescentOptimizer(1e-2),tf.nn.leaky_relu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./s5/layer1_1.PNG\" alt=\"Drawing\" style=\"width: 1500px;\"/>\n",
    "<img src=\"./s5/layer1_2.PNG\" alt=\"Drawing\" style=\"width: 1500px;\"/>\n",
    "<img src=\"./s5/hist_layer1.PNG\" alt=\"Drawing\" style=\"width: 1500px;\"/>\n",
    "<img src=\"./s5/layer2_1.PNG\" alt=\"Drawing\" style=\"width: 1500px;\"/>\n",
    "<img src=\"./s5/layer2_2.PNG\" alt=\"Drawing\" style=\"width: 1500px;\"/>\n",
    "<img src=\"./s5/hist_layer2.PNG\" alt=\"Drawing\" style=\"width: 1500px;\"/>\n",
    "<img src=\"./s5/layerfc1_1.PNG\" alt=\"Drawing\" style=\"width: 1500px;\"/>\n",
    "<img src=\"./s5/layerfc1_2.PNG\" alt=\"Drawing\" style=\"width: 1500px;\"/>\n",
    "<img src=\"./s5/hist_layerfc1.PNG\" alt=\"Drawing\" style=\"width: 1500px;\"/>\n",
    "<img src=\"./s5/layerfc2_1.PNG\" alt=\"Drawing\" style=\"width: 1500px;\"/>\n",
    "<img src=\"./s5/layerfc2_2.PNG\" alt=\"Drawing\" style=\"width: 1500px;\"/>\n",
    "<img src=\"./s5/hist_layerfc2.PNG\" alt=\"Drawing\" style=\"width: 1500px;\"/>\n",
    "<img src=\"./s5/test_ac.PNG\" alt=\"Drawing\" style=\"width: 550px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mSetup #6:\u001b[0m \u001b[91m AdagradOptimizer, leaky_relu activation\u001b[00m\n",
      "step 0, training accuracy 0.0958\n",
      "step 100, training accuracy 0.1219\n",
      "step 200, training accuracy 0.7981\n",
      "step 300, training accuracy 0.8798\n",
      "step 400, training accuracy 0.9167\n",
      "step 500, training accuracy 0.9264\n",
      "step 600, training accuracy 0.9415\n",
      "step 700, training accuracy 0.9479\n",
      "step 800, training accuracy 0.9553\n",
      "step 900, training accuracy 0.9556\n",
      "step 1000, training accuracy 0.9627\n",
      "step 1100, training accuracy 0.9641\n",
      "step 1200, training accuracy 0.9549\n",
      "step 1300, training accuracy 0.9687\n",
      "step 1400, training accuracy 0.9675\n",
      "step 1500, training accuracy 0.9691\n",
      "step 1600, training accuracy 0.969\n",
      "step 1700, training accuracy 0.9683\n",
      "step 1800, training accuracy 0.975\n",
      "step 1900, training accuracy 0.9736\n",
      "step 2000, training accuracy 0.9737\n",
      "step 2100, training accuracy 0.9778\n",
      "step 2200, training accuracy 0.9759\n",
      "step 2300, training accuracy 0.976\n",
      "step 2400, training accuracy 0.9776\n",
      "step 2500, training accuracy 0.9776\n",
      "step 2600, training accuracy 0.9799\n",
      "step 2700, training accuracy 0.9807\n",
      "step 2800, training accuracy 0.9794\n",
      "step 2900, training accuracy 0.9796\n",
      "step 3000, training accuracy 0.9803\n",
      "step 3100, training accuracy 0.9815\n",
      "step 3200, training accuracy 0.9809\n",
      "step 3300, training accuracy 0.9828\n",
      "step 3400, training accuracy 0.9823\n",
      "step 3500, training accuracy 0.9815\n",
      "step 3600, training accuracy 0.9813\n",
      "step 3700, training accuracy 0.983\n",
      "step 3800, training accuracy 0.9833\n",
      "step 3900, training accuracy 0.9824\n",
      "step 4000, training accuracy 0.9831\n",
      "step 4100, training accuracy 0.9836\n",
      "step 4200, training accuracy 0.9851\n",
      "step 4300, training accuracy 0.9807\n",
      "step 4400, training accuracy 0.9848\n",
      "step 4500, training accuracy 0.9852\n",
      "step 4600, training accuracy 0.9843\n",
      "step 4700, training accuracy 0.9854\n",
      "step 4800, training accuracy 0.9859\n",
      "step 4900, training accuracy 0.9853\n",
      "step 5000, training accuracy 0.9862\n",
      "step 5100, training accuracy 0.9878\n",
      "step 5200, training accuracy 0.9865\n",
      "step 5300, training accuracy 0.9861\n",
      "step 5400, training accuracy 0.9886\n",
      "test accuracy 0.9873\n",
      "The training takes 215.800522 second to finish\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    case = \"{}{}{}\".format(bold,\"Setup #6:\",bolde)\n",
    "    print(case,red_color.format(\"AdagradOptimizer, leaky_relu activation\"))\n",
    "    tf.reset_default_graph() \n",
    "    sess = tf.InteractiveSession()\n",
    "    main_new(tf.train.AdagradOptimizer(5e-2,2),tf.nn.leaky_relu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./s6/layer1_1.PNG\" alt=\"Drawing\" style=\"width: 1500px;\"/>\n",
    "<img src=\"./s6/layer1_2.PNG\" alt=\"Drawing\" style=\"width: 1500px;\"/>\n",
    "<img src=\"./s6/hist_layer1.PNG\" alt=\"Drawing\" style=\"width: 1500px;\"/>\n",
    "<img src=\"./s6/layer2_1.PNG\" alt=\"Drawing\" style=\"width: 1500px;\"/>\n",
    "<img src=\"./s6/layer2_2.PNG\" alt=\"Drawing\" style=\"width: 1500px;\"/>\n",
    "<img src=\"./s6/hist_layer2.PNG\" alt=\"Drawing\" style=\"width: 1500px;\"/>\n",
    "<img src=\"./s6/layerfc1_1.PNG\" alt=\"Drawing\" style=\"width: 1500px;\"/>\n",
    "<img src=\"./s6/layerfc1_2.PNG\" alt=\"Drawing\" style=\"width: 1500px;\"/>\n",
    "<img src=\"./s6/hist_layerfc1.PNG\" alt=\"Drawing\" style=\"width: 1500px;\"/>\n",
    "<img src=\"./s6/layerfc2_1.PNG\" alt=\"Drawing\" style=\"width: 1500px;\"/>\n",
    "<img src=\"./s6/layerfc2_2.PNG\" alt=\"Drawing\" style=\"width: 1500px;\"/>\n",
    "<img src=\"./s6/hist_layerfc2.PNG\" alt=\"Drawing\" style=\"width: 1500px;\"/>\n",
    "<img src=\"./s6/test_ac.PNG\" alt=\"Drawing\" style=\"width: 550px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.c. continued: Describe what you observe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part really depends on the set of parameters (activation function, learning algorithm, ...) one has picked for comparison, so based on the parameters I chose, there are a couple of interesting things to note:\n",
    "1. Adagrad and Gradient Descent perform almost the same in all setups. i.e., when everything is fixed, the final accuracy of these two methods is pretty close. This can be understood by comparing setup #1 with setup #2, or setup #3 with setup #4, or setup #5 with setup #6.\n",
    "2. Sigmoid is the worst function among the ones I tested in terms of stability and final test as well as train accuracy. As you may see in the result of setup #3 or #4, for the first 1700 iterations, the training accuracy goes back and forth and wanders around %10.\n",
    "3. Based on the result of setup #5, if leaky_ReLu is chosen as the activation function, a smaller learning rate is needed to use the Gradient Descent compared with setup #1 where tanh is employed.\n",
    "4. To wrap up the accuracy discussion, GradientDecent alongside with tanh is the best choice of parameters when using the variance scaling initializer."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
